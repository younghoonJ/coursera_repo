{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQNgXdiP2ItJ"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jqs9gy-2ItL",
        "outputId": "c4e3ab18-f722-40a5-d0ca-61b5fb4045c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrnZhOXp2ItM"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlcOgGCL2ItM"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kct6ySl72ItM"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = np.max([self.get_qvalue(state, a) for a in possible_actions])\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        qv = (1 - learning_rate) * self.get_qvalue(state, action) + learning_rate * (reward + gamma * self.get_value(next_state))\n",
        "\n",
        "        self.set_qvalue(state, action, qv)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        idx = np.argmax([self.get_qvalue(state, a) for a in possible_actions])\n",
        "        best_action = possible_actions[idx]\n",
        "\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.getPolicy).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        if np.random.random() < epsilon:\n",
        "          chosen_action = np.random.choice(possible_actions)\n",
        "        else:\n",
        "          chosen_action = self.get_best_action(state)\n",
        "\n",
        "        return chosen_action"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kma3BvLU2ItN"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYmxw2092ItO"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        n_actions = len(possible_actions)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if n_actions == 0:\n",
        "            return 0.0\n",
        "\n",
        "        if n_actions > 1:\n",
        "          state_value = 0.0\n",
        "          prob_best = epsilon\n",
        "          prob_else = (1 - epsilon) / (n_actions - 1)\n",
        "          for a in possible_actions:\n",
        "            if a == self.get_best_action(state):\n",
        "              state_value += self.get_qvalue(state, a) * prob_best\n",
        "            else:\n",
        "              state_value += self.get_qvalue(state, a) * prob_else\n",
        "        else:\n",
        "          state_value = self.get_qvalue(state, possible_actions[0])\n",
        "\n",
        "        return state_value"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KSEOFmQ2ItO"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o77bGWta2ItO",
        "outputId": "a8de80e0-9baa-49ea-8448-2c68fc067987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u18el8qz2ItO",
        "outputId": "9a192524-81b0-4361-9bf6-8ae13a4081b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovLKFOrj2ItP"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JugDBs12ItP"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug1tzNUV2ItP",
        "outputId": "dc476625-31af-4c80-bf22-38cf4181e32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVSARSA mean reward = -36.27\n",
            "QLEARNING mean reward = -91.69\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aihGjTs2ItQ"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRy8OSDQ2ItQ"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfwVcyvK2ItQ",
        "outputId": "491ed6df-46bc-49fb-e595-874df8c782fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-Learning\n",
            " v  v  v  >  >  >  v  v  >  v  v  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  >  >  >  >  ^  >  >  >  ^  >  v \n",
            " ^  ^  ^  >  ^  ^  ^  ^  ^  <  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SnVnjt12ItQ"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAQoPd6n2ItR"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}